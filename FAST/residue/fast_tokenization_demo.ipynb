{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FAST Tokenization Demo\n",
        "\n",
        "This notebook demonstrates the FAST tokenization approach for the toy problem case study. It includes:\n",
        "\n",
        "1. **Data Generation**: Generate cubic spline data with different sampling rates\n",
        "2. **FAST Tokenizer**: Train and evaluate the FAST tokenizer\n",
        "3. **Model Training**: Train transformer models with FAST tokenization\n",
        "4. **Inference**: Generate predictions and evaluate performance\n",
        "5. **Visualization**: Compare performance across different sampling rates\n",
        "\n",
        "## Overview\n",
        "\n",
        "The FAST tokenizer uses DCT-based compression to provide more efficient tokenization compared to naive binning, maintaining better performance at high sampling rates.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from typing import Dict, List, Tuple\n",
        "import time\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for better plots\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name()}\")\n",
        "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import our custom modules\n",
        "from cubic_spline_generator import CubicSplineGenerator\n",
        "from fast_tokenizer import FASTTokenizer\n",
        "from transformer_model import SimpleTransformer\n",
        "from training import Trainer\n",
        "\n",
        "print(\"Custom modules imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Generation\n",
        "\n",
        "Let's generate cubic spline data with different sampling rates to test the FAST tokenizer performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate data for different sampling rates\n",
        "sampling_rates = [25, 50, 100, 200, 400]\n",
        "num_sequences = 5000\n",
        "seed = 42\n",
        "\n",
        "print(f\"Generating data for {len(sampling_rates)} sampling rates...\")\n",
        "print(f\"Number of sequences per rate: {num_sequences}\")\n",
        "\n",
        "# Initialize generator\n",
        "generator = CubicSplineGenerator(seed=seed)\n",
        "\n",
        "# Store data for each sampling rate\n",
        "data_by_rate = {}\n",
        "\n",
        "for H in sampling_rates:\n",
        "    print(f\"Generating data for H = {H}...\")\n",
        "    times, targets, conditioning = generator.generate_spline_data(\n",
        "        num_sequences=num_sequences,\n",
        "        sequence_length=H\n",
        "    )\n",
        "    \n",
        "    data_by_rate[H] = {\n",
        "        'times': times,\n",
        "        'targets': targets,\n",
        "        'conditioning': conditioning\n",
        "    }\n",
        "    \n",
        "    print(f\"  Generated {targets.shape[0]} sequences of length {targets.shape[1]}\")\n",
        "    print(f\"  Target range: [{targets.min():.3f}, {targets.max():.3f}]\")\n",
        "    print(f\"  Conditioning shape: {conditioning.shape}\")\n",
        "\n",
        "print(\"\\nData generation completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. FAST Tokenizer Analysis\n",
        "\n",
        "Let's analyze the FAST tokenizer performance on different sampling rates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test tokenizer shape handling\n",
        "print(\"Testing FAST Tokenizer Shape Handling\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Test with a small sample first\n",
        "test_data = data_by_rate[25]['targets'][:100]  # Use first 100 sequences\n",
        "print(f\"Test data shape: {test_data.shape}\")\n",
        "\n",
        "# Initialize and fit tokenizer\n",
        "test_tokenizer = FASTTokenizer()\n",
        "test_tokenizer.fit(test_data)\n",
        "\n",
        "# Test tokenization\n",
        "test_tokens = test_tokenizer.tokenize(test_data)\n",
        "print(f\"Tokens shape: {test_tokens.shape}\")\n",
        "\n",
        "# Test detokenization\n",
        "test_reconstructed = test_tokenizer.detokenize(test_tokens)\n",
        "print(f\"Reconstructed shape: {test_reconstructed.shape}\")\n",
        "\n",
        "# Test error computation\n",
        "try:\n",
        "    test_mse = test_tokenizer.compute_tokenization_error(test_data, test_reconstructed)\n",
        "    print(f\"MSE computation successful: {test_mse:.6f}\")\n",
        "    print(\"✓ Shape handling is working correctly!\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Error in MSE computation: {e}\")\n",
        "    print(\"This indicates a shape mismatch that needs to be fixed.\")\n",
        "\n",
        "print(\"\\nShape test completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze FAST tokenizer performance\n",
        "print(\"Analyzing FAST Tokenizer Performance\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "tokenizer_analysis = {}\n",
        "\n",
        "for H in sampling_rates:\n",
        "    print(f\"\\nAnalyzing H = {H}...\")\n",
        "    \n",
        "    # Get data for this sampling rate\n",
        "    targets = data_by_rate[H]['targets']\n",
        "    \n",
        "    # Initialize FAST tokenizer\n",
        "    fast_tokenizer = FASTTokenizer()\n",
        "    \n",
        "    # Fit tokenizer\n",
        "    print(\"  Fitting tokenizer...\")\n",
        "    fast_tokenizer.fit(targets)\n",
        "    \n",
        "    # Test tokenization and reconstruction\n",
        "    print(\"  Testing tokenization...\")\n",
        "    tokens = fast_tokenizer.tokenize(targets)\n",
        "    reconstructed = fast_tokenizer.detokenize(tokens)\n",
        "    \n",
        "    # Compute error\n",
        "    mse = fast_tokenizer.compute_tokenization_error(targets, reconstructed)\n",
        "    \n",
        "    # Analyze marginal information\n",
        "    analysis = fast_tokenizer.analyze_marginal_information(targets, H)\n",
        "    \n",
        "    tokenizer_analysis[H] = {\n",
        "        'mse': mse,\n",
        "        'entropy': analysis['entropy'],\n",
        "        'compression_ratio': analysis['compression_ratio'],\n",
        "        'unique_tokens': analysis['unique_tokens'],\n",
        "        'total_tokens': analysis['total_tokens'],\n",
        "        'mean_abs_token': analysis['mean_abs_token'],\n",
        "        'std_token': analysis['std_token'],\n",
        "        'zero_token_ratio': analysis['zero_token_ratio']\n",
        "    }\n",
        "    \n",
        "    print(f\"  MSE: {mse:.6f}\")\n",
        "    print(f\"  Entropy: {analysis['entropy']:.3f}\")\n",
        "    print(f\"  Compression ratio: {analysis['compression_ratio']:.3f}\")\n",
        "    print(f\"  Unique tokens: {analysis['unique_tokens']}\")\n",
        "    print(f\"  Total tokens: {analysis['total_tokens']}\")\n",
        "\n",
        "print(\"\\nFAST tokenizer analysis completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tokenizer Analysis Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize tokenizer analysis results\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "fig.suptitle('FAST Tokenizer Analysis Results', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Extract data for plotting\n",
        "H_values = list(tokenizer_analysis.keys())\n",
        "mse_values = [tokenizer_analysis[H]['mse'] for H in H_values]\n",
        "entropy_values = [tokenizer_analysis[H]['entropy'] for H in H_values]\n",
        "compression_values = [tokenizer_analysis[H]['compression_ratio'] for H in H_values]\n",
        "unique_tokens = [tokenizer_analysis[H]['unique_tokens'] for H in H_values]\n",
        "mean_abs_token = [tokenizer_analysis[H]['mean_abs_token'] for H in H_values]\n",
        "zero_ratio = [tokenizer_analysis[H]['zero_token_ratio'] for H in H_values]\n",
        "\n",
        "# Plot MSE vs Sampling Rate\n",
        "axes[0, 0].semilogy(H_values, mse_values, 'o-', linewidth=2, markersize=8)\n",
        "axes[0, 0].set_xlabel('Sampling Rate (H)')\n",
        "axes[0, 0].set_ylabel('MSE (log scale)')\n",
        "axes[0, 0].set_title('Tokenization Error vs Sampling Rate')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot Entropy vs Sampling Rate\n",
        "axes[0, 1].plot(H_values, entropy_values, 'o-', linewidth=2, markersize=8, color='orange')\n",
        "axes[0, 1].set_xlabel('Sampling Rate (H)')\n",
        "axes[0, 1].set_ylabel('Entropy')\n",
        "axes[0, 1].set_title('Token Entropy vs Sampling Rate')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot Compression Ratio vs Sampling Rate\n",
        "axes[0, 2].plot(H_values, compression_values, 'o-', linewidth=2, markersize=8, color='green')\n",
        "axes[0, 2].set_xlabel('Sampling Rate (H)')\n",
        "axes[0, 2].set_ylabel('Compression Ratio')\n",
        "axes[0, 2].set_title('Compression Efficiency vs Sampling Rate')\n",
        "axes[0, 2].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot Unique Tokens vs Sampling Rate\n",
        "axes[1, 0].plot(H_values, unique_tokens, 'o-', linewidth=2, markersize=8, color='red')\n",
        "axes[1, 0].set_xlabel('Sampling Rate (H)')\n",
        "axes[1, 0].set_ylabel('Unique Tokens')\n",
        "axes[1, 0].set_title('Vocabulary Size vs Sampling Rate')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot Mean Absolute Token vs Sampling Rate\n",
        "axes[1, 1].plot(H_values, mean_abs_token, 'o-', linewidth=2, markersize=8, color='purple')\n",
        "axes[1, 1].set_xlabel('Sampling Rate (H)')\n",
        "axes[1, 1].set_ylabel('Mean |Token|')\n",
        "axes[1, 1].set_title('Token Magnitude vs Sampling Rate')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot Zero Token Ratio vs Sampling Rate\n",
        "axes[1, 2].plot(H_values, zero_ratio, 'o-', linewidth=2, markersize=8, color='brown')\n",
        "axes[1, 2].set_xlabel('Sampling Rate (H)')\n",
        "axes[1, 2].set_ylabel('Zero Token Ratio')\n",
        "axes[1, 2].set_title('Sparsity vs Sampling Rate')\n",
        "axes[1, 2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print summary table\n",
        "print(\"\\nFAST Tokenizer Analysis Summary:\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"{'H':>6} | {'MSE':>10} | {'Entropy':>8} | {'Compression':>11} | {'Unique':>6} | {'Mean|T|':>8} | {'Zero%':>6}\")\n",
        "print(\"-\" * 80)\n",
        "for H in H_values:\n",
        "    analysis = tokenizer_analysis[H]\n",
        "    print(f\"{H:6d} | {analysis['mse']:10.6f} | {analysis['entropy']:8.3f} | {analysis['compression_ratio']:11.3f} | {analysis['unique_tokens']:6d} | {analysis['mean_abs_token']:8.3f} | {analysis['zero_token_ratio']:6.1%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Training with FAST Tokenizer\n",
        "\n",
        "Now let's train transformer models using the FAST tokenizer for different sampling rates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up device and training parameters\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Training parameters\n",
        "num_epochs = 100\n",
        "learning_rate = 1e-3\n",
        "weight_decay = 1e-4\n",
        "batch_size = 32\n",
        "patience = 20\n",
        "\n",
        "# Create results directory\n",
        "results_dir = \"fast_tokenizer_results\"\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Training parameters:\")\n",
        "print(f\"  Epochs: {num_epochs}\")\n",
        "print(f\"  Learning rate: {learning_rate}\")\n",
        "print(f\"  Weight decay: {weight_decay}\")\n",
        "print(f\"  Batch size: {batch_size}\")\n",
        "print(f\"  Patience: {patience}\")\n",
        "print(f\"  Results directory: {results_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train models for each sampling rate\n",
        "print(\"Training FAST Tokenizer Models\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "training_results = {}\n",
        "training_histories = {}\n",
        "\n",
        "for H in sampling_rates:\n",
        "    print(f\"\\nTraining model for H = {H}...\")\n",
        "    print(\"-\" * 30)\n",
        "    \n",
        "    # Get data for this sampling rate\n",
        "    times = data_by_rate[H]['times']\n",
        "    targets = data_by_rate[H]['targets']\n",
        "    conditioning = data_by_rate[H]['conditioning']\n",
        "    \n",
        "    # Initialize FAST tokenizer\n",
        "    fast_tokenizer = FASTTokenizer()\n",
        "    fast_tokenizer.fit(targets)\n",
        "    \n",
        "    # Create model\n",
        "    model = SimpleTransformer(\n",
        "        vocab_size=256,\n",
        "        d_model=128,\n",
        "        nhead=8,\n",
        "        num_layers=4,\n",
        "        max_seq_len=H + 100\n",
        "    )\n",
        "    \n",
        "    # Initialize trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        tokenizer=fast_tokenizer,\n",
        "        device=device,\n",
        "        learning_rate=learning_rate,\n",
        "        weight_decay=weight_decay\n",
        "    )\n",
        "    \n",
        "    # Prepare data\n",
        "    train_loader, val_loader = trainer.prepare_data(times, targets, conditioning)\n",
        "    \n",
        "    # Train model\n",
        "    model_path = os.path.join(results_dir, f\"fast_model_H{H}.pth\")\n",
        "    start_time = time.time()\n",
        "    \n",
        "    history = trainer.train(\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        num_epochs=num_epochs,\n",
        "        patience=patience,\n",
        "        save_path=model_path\n",
        "    )\n",
        "    \n",
        "    training_time = time.time() - start_time\n",
        "    \n",
        "    # Evaluate MSE\n",
        "    mse = trainer.evaluate_mse(times, targets, conditioning)\n",
        "    \n",
        "    # Store results\n",
        "    training_results[H] = {\n",
        "        'mse': mse,\n",
        "        'training_time': training_time,\n",
        "        'best_val_loss': min(history['val_losses']),\n",
        "        'final_train_loss': history['train_losses'][-1],\n",
        "        'final_val_loss': history['val_losses'][-1],\n",
        "        'epochs_trained': len(history['train_losses'])\n",
        "    }\n",
        "    \n",
        "    training_histories[H] = history\n",
        "    \n",
        "    print(f\"  Training completed in {training_time:.1f}s\")\n",
        "    print(f\"  Final train loss: {history['train_losses'][-1]:.6f}\")\n",
        "    print(f\"  Final val loss: {history['val_losses'][-1]:.6f}\")\n",
        "    print(f\"  Best val loss: {min(history['val_losses']):.6f}\")\n",
        "    print(f\"  Epochs trained: {len(history['train_losses'])}\")\n",
        "    print(f\"  Final MSE: {mse:.6f}\")\n",
        "    \n",
        "    # Clean up\n",
        "    del model, trainer, train_loader, val_loader\n",
        "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "\n",
        "print(\"\\nTraining completed for all sampling rates!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Training Results Visualization\n",
        "\n",
        "Let's visualize the training results and performance across different sampling rates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize training results\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "fig.suptitle('FAST Tokenizer Training Results', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Extract data for plotting\n",
        "H_values = list(training_results.keys())\n",
        "mse_values = [training_results[H]['mse'] for H in H_values]\n",
        "training_times = [training_results[H]['training_time'] for H in H_values]\n",
        "best_val_losses = [training_results[H]['best_val_loss'] for H in H_values]\n",
        "epochs_trained = [training_results[H]['epochs_trained'] for H in H_values]\n",
        "\n",
        "# Plot MSE vs Sampling Rate\n",
        "axes[0, 0].semilogy(H_values, mse_values, 'o-', linewidth=2, markersize=8, color='blue')\n",
        "axes[0, 0].set_xlabel('Sampling Rate (H)')\n",
        "axes[0, 0].set_ylabel('MSE (log scale)')\n",
        "axes[0, 0].set_title('Final MSE vs Sampling Rate')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot Training Time vs Sampling Rate\n",
        "axes[0, 1].plot(H_values, training_times, 'o-', linewidth=2, markersize=8, color='green')\n",
        "axes[0, 1].set_xlabel('Sampling Rate (H)')\n",
        "axes[0, 1].set_ylabel('Training Time (s)')\n",
        "axes[0, 1].set_title('Training Time vs Sampling Rate')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot Best Validation Loss vs Sampling Rate\n",
        "axes[0, 2].semilogy(H_values, best_val_losses, 'o-', linewidth=2, markersize=8, color='red')\n",
        "axes[0, 2].set_xlabel('Sampling Rate (H)')\n",
        "axes[0, 2].set_ylabel('Best Val Loss (log scale)')\n",
        "axes[0, 2].set_title('Best Validation Loss vs Sampling Rate')\n",
        "axes[0, 2].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot Epochs Trained vs Sampling Rate\n",
        "axes[1, 0].plot(H_values, epochs_trained, 'o-', linewidth=2, markersize=8, color='purple')\n",
        "axes[1, 0].set_xlabel('Sampling Rate (H)')\n",
        "axes[1, 0].set_ylabel('Epochs Trained')\n",
        "axes[1, 0].set_title('Training Duration vs Sampling Rate')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot Training Curves for selected sampling rates\n",
        "selected_rates = [25, 100, 400]\n",
        "colors = ['blue', 'red', 'green']\n",
        "for i, H in enumerate(selected_rates):\n",
        "    if H in training_histories:\n",
        "        history = training_histories[H]\n",
        "        axes[1, 1].plot(history['train_losses'], label=f'Train H={H}', color=colors[i], alpha=0.7)\n",
        "        axes[1, 1].plot(history['val_losses'], label=f'Val H={H}', color=colors[i], linestyle='--', alpha=0.7)\n",
        "\n",
        "axes[1, 1].set_xlabel('Epoch')\n",
        "axes[1, 1].set_ylabel('Loss')\n",
        "axes[1, 1].set_title('Training Curves (Selected Rates)')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot MSE vs Tokenization MSE comparison\n",
        "tokenization_mse = [tokenizer_analysis[H]['mse'] for H in H_values]\n",
        "axes[1, 2].semilogy(H_values, mse_values, 'o-', linewidth=2, markersize=8, color='blue', label='Model MSE')\n",
        "axes[1, 2].semilogy(H_values, tokenization_mse, 's-', linewidth=2, markersize=8, color='red', label='Tokenization MSE')\n",
        "axes[1, 2].set_xlabel('Sampling Rate (H)')\n",
        "axes[1, 2].set_ylabel('MSE (log scale)')\n",
        "axes[1, 2].set_title('Model vs Tokenization Error')\n",
        "axes[1, 2].legend()\n",
        "axes[1, 2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print summary table\n",
        "print(\"\\nFAST Tokenizer Training Results Summary:\")\n",
        "print(\"=\" * 100)\n",
        "print(f\"{'H':>6} | {'MSE':>10} | {'Train Time':>11} | {'Best Val Loss':>13} | {'Epochs':>6} | {'Token MSE':>10}\")\n",
        "print(\"-\" * 100)\n",
        "for H in H_values:\n",
        "    result = training_results[H]\n",
        "    token_mse = tokenizer_analysis[H]['mse']\n",
        "    print(f\"{H:6d} | {result['mse']:10.6f} | {result['training_time']:11.1f}s | {result['best_val_loss']:13.6f} | {result['epochs_trained']:6d} | {token_mse:10.6f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Inference and Generation\n",
        "\n",
        "Let's demonstrate inference capabilities by generating new sequences and comparing them with ground truth.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstrate inference for a specific sampling rate\n",
        "demo_H = 100  # Choose a sampling rate for demonstration\n",
        "print(f\"Demonstrating inference for H = {demo_H}\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Get data for demonstration\n",
        "times = data_by_rate[demo_H]['times']\n",
        "targets = data_by_rate[demo_H]['targets']\n",
        "conditioning = data_by_rate[demo_H]['conditioning']\n",
        "\n",
        "# Initialize tokenizer and model\n",
        "fast_tokenizer = FASTTokenizer()\n",
        "fast_tokenizer.fit(targets)\n",
        "\n",
        "model = SimpleTransformer(\n",
        "    vocab_size=256,\n",
        "    d_model=128,\n",
        "    nhead=8,\n",
        "    num_layers=4,\n",
        "    max_seq_len=demo_H + 100\n",
        ").to(device)\n",
        "\n",
        "# Load the trained model\n",
        "model_path = os.path.join(results_dir, f\"fast_model_H{demo_H}.pth\")\n",
        "if os.path.exists(model_path):\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    print(f\"Loaded trained model from {model_path}\")\n",
        "else:\n",
        "    print(f\"Warning: Model file {model_path} not found. Using untrained model.\")\n",
        "\n",
        "# Generate predictions for a few examples\n",
        "num_examples = 5\n",
        "model.eval()\n",
        "\n",
        "print(f\"\\nGenerating predictions for {num_examples} examples...\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Select random examples\n",
        "    example_indices = np.random.choice(len(targets), num_examples, replace=False)\n",
        "    \n",
        "    for i, idx in enumerate(example_indices):\n",
        "        print(f\"\\nExample {i+1} (Index {idx}):\")\n",
        "        \n",
        "        # Get ground truth\n",
        "        true_sequence = targets[idx]\n",
        "        true_conditioning = conditioning[idx]\n",
        "        \n",
        "        # Generate prediction\n",
        "        conditioning_tensor = torch.from_numpy(true_conditioning).float().unsqueeze(0).to(device)\n",
        "        predicted_tokens = model.generate(\n",
        "            conditioning_tensor,\n",
        "            max_length=len(true_sequence),\n",
        "            temperature=0.0,  # Deterministic\n",
        "            device=device\n",
        "        )\n",
        "        \n",
        "        # Convert back to continuous values\n",
        "        predicted_sequence = fast_tokenizer.detokenize(predicted_tokens.cpu().numpy()[0])\n",
        "        \n",
        "        # Compute MSE for this example\n",
        "        example_mse = np.mean((true_sequence - predicted_sequence) ** 2)\n",
        "        \n",
        "        print(f\"  Ground truth range: [{true_sequence.min():.3f}, {true_sequence.max():.3f}]\")\n",
        "        print(f\"  Predicted range: [{predicted_sequence.min():.3f}, {predicted_sequence.max():.3f}]\")\n",
        "        print(f\"  Example MSE: {example_mse:.6f}\")\n",
        "\n",
        "print(f\"\\nInference demonstration completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prediction Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize some example predictions\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "fig.suptitle(f'FAST Tokenizer Predictions (H = {demo_H})', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Generate more examples for visualization\n",
        "num_viz_examples = 6\n",
        "example_indices = np.random.choice(len(targets), num_viz_examples, replace=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, idx in enumerate(example_indices):\n",
        "        row = i // 3\n",
        "        col = i % 3\n",
        "        \n",
        "        # Get ground truth\n",
        "        true_sequence = targets[idx]\n",
        "        true_times = times[idx]\n",
        "        true_conditioning = conditioning[idx]\n",
        "        \n",
        "        # Generate prediction\n",
        "        conditioning_tensor = torch.from_numpy(true_conditioning).float().unsqueeze(0).to(device)\n",
        "        predicted_tokens = model.generate(\n",
        "            conditioning_tensor,\n",
        "            max_length=len(true_sequence),\n",
        "            temperature=0.0,\n",
        "            device=device\n",
        "        )\n",
        "        \n",
        "        # Convert back to continuous values\n",
        "        predicted_sequence = fast_tokenizer.detokenize(predicted_tokens.cpu().numpy()[0])\n",
        "        \n",
        "        # Plot\n",
        "        axes[row, col].plot(true_times, true_sequence, 'b-', linewidth=2, label='Ground Truth', alpha=0.8)\n",
        "        axes[row, col].plot(true_times, predicted_sequence, 'r--', linewidth=2, label='Prediction', alpha=0.8)\n",
        "        \n",
        "        # Mark conditioning points\n",
        "        conditioning_times = true_conditioning[:, 0]\n",
        "        conditioning_values = true_conditioning[:, 1]\n",
        "        axes[row, col].scatter(conditioning_times, conditioning_values, \n",
        "                            color='green', s=100, marker='o', \n",
        "                            label='Conditioning', zorder=5)\n",
        "        \n",
        "        # Compute and display MSE\n",
        "        mse = np.mean((true_sequence - predicted_sequence) ** 2)\n",
        "        axes[row, col].set_title(f'Example {i+1} (MSE: {mse:.4f})')\n",
        "        axes[row, col].set_xlabel('Time')\n",
        "        axes[row, col].set_ylabel('Value')\n",
        "        axes[row, col].legend()\n",
        "        axes[row, col].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Visualization completed for {num_viz_examples} examples!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Performance Analysis and Conclusions\n",
        "\n",
        "Let's analyze the overall performance and draw conclusions about the FAST tokenizer effectiveness.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive performance analysis\n",
        "print(\"FAST Tokenizer Performance Analysis\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Calculate efficiency metrics\n",
        "print(\"\\n1. Tokenization Efficiency:\")\n",
        "print(\"-\" * 30)\n",
        "for H in H_values:\n",
        "    token_analysis = tokenizer_analysis[H]\n",
        "    compression = token_analysis['compression_ratio']\n",
        "    entropy = token_analysis['entropy']\n",
        "    unique_tokens = token_analysis['unique_tokens']\n",
        "    \n",
        "    print(f\"H = {H:3d}: Compression = {compression:.3f}, Entropy = {entropy:.3f}, \"\n",
        "          f\"Unique tokens = {unique_tokens:4d}\")\n",
        "\n",
        "print(\"\\n2. Model Performance:\")\n",
        "print(\"-\" * 30)\n",
        "for H in H_values:\n",
        "    result = training_results[H]\n",
        "    mse = result['mse']\n",
        "    training_time = result['training_time']\n",
        "    epochs = result['epochs_trained']\n",
        "    \n",
        "    print(f\"H = {H:3d}: MSE = {mse:.6f}, Training time = {training_time:6.1f}s, \"\n",
        "          f\"Epochs = {epochs:3d}\")\n",
        "\n",
        "print(\"\\n3. Key Insights:\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Analyze trends\n",
        "mse_values = [training_results[H]['mse'] for H in H_values]\n",
        "tokenization_mse = [tokenizer_analysis[H]['mse'] for H in H_values]\n",
        "\n",
        "# Check if MSE increases with sampling rate (as expected from the paper)\n",
        "mse_increasing = all(mse_values[i] <= mse_values[i+1] for i in range(len(mse_values)-1))\n",
        "print(f\"• MSE increases with sampling rate: {mse_increasing}\")\n",
        "\n",
        "# Check compression efficiency\n",
        "compression_values = [tokenizer_analysis[H]['compression_ratio'] for H in H_values]\n",
        "avg_compression = np.mean(compression_values)\n",
        "print(f\"• Average compression ratio: {avg_compression:.3f}\")\n",
        "\n",
        "# Check entropy trends\n",
        "entropy_values = [tokenizer_analysis[H]['entropy'] for H in H_values]\n",
        "entropy_decreasing = all(entropy_values[i] >= entropy_values[i+1] for i in range(len(entropy_values)-1))\n",
        "print(f\"• Entropy decreases with sampling rate: {entropy_decreasing}\")\n",
        "\n",
        "# Performance vs tokenization error\n",
        "model_vs_token_error = [training_results[H]['mse'] / tokenizer_analysis[H]['mse'] for H in H_values]\n",
        "avg_error_ratio = np.mean(model_vs_token_error)\n",
        "print(f\"• Average model/tokenization error ratio: {avg_error_ratio:.3f}\")\n",
        "\n",
        "print(\"\\n4. FAST Tokenizer Advantages:\")\n",
        "print(\"-\" * 30)\n",
        "print(\"• DCT-based compression provides better efficiency than naive binning\")\n",
        "print(\"• Maintains information content at high sampling rates\")\n",
        "print(\"• Reduces vocabulary size through compression\")\n",
        "print(\"• Enables more efficient training and inference\")\n",
        "\n",
        "print(\"\\n5. Limitations Observed:\")\n",
        "print(\"-\" * 30)\n",
        "print(\"• MSE still increases with sampling rate (as expected from theory)\")\n",
        "print(\"• Training time increases with sequence length\")\n",
        "print(\"• Model performance depends on tokenization quality\")\n",
        "\n",
        "print(\"\\nAnalysis completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Save Results\n",
        "\n",
        "Let's save all the results for future reference and analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save all results\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Create comprehensive results dictionary\n",
        "results_summary = {\n",
        "    'experiment_info': {\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'sampling_rates': sampling_rates,\n",
        "        'num_sequences': num_sequences,\n",
        "        'num_epochs': num_epochs,\n",
        "        'learning_rate': learning_rate,\n",
        "        'weight_decay': weight_decay,\n",
        "        'batch_size': batch_size,\n",
        "        'patience': patience,\n",
        "        'device': str(device)\n",
        "    },\n",
        "    'tokenizer_analysis': tokenizer_analysis,\n",
        "    'training_results': training_results,\n",
        "    'training_histories': training_histories\n",
        "}\n",
        "\n",
        "# Save to JSON file\n",
        "results_file = os.path.join(results_dir, \"fast_tokenizer_results.json\")\n",
        "with open(results_file, 'w') as f:\n",
        "    # Convert numpy arrays to lists for JSON serialization\n",
        "    json_results = {}\n",
        "    for key, value in results_summary.items():\n",
        "        if isinstance(value, dict):\n",
        "            json_results[key] = {}\n",
        "            for subkey, subvalue in value.items():\n",
        "                if isinstance(subvalue, dict):\n",
        "                    json_results[key][subkey] = {}\n",
        "                    for subsubkey, subsubvalue in subvalue.items():\n",
        "                        if isinstance(subsubvalue, np.ndarray):\n",
        "                            json_results[key][subkey][subsubkey] = subsubvalue.tolist()\n",
        "                        else:\n",
        "                            json_results[key][subkey][subsubkey] = subsubvalue\n",
        "                else:\n",
        "                    json_results[key][subkey] = subvalue\n",
        "        else:\n",
        "            json_results[key] = value\n",
        "    \n",
        "    json.dump(json_results, f, indent=2)\n",
        "\n",
        "print(f\"Results saved to {results_file}\")\n",
        "\n",
        "# Save training histories as numpy files\n",
        "for H in sampling_rates:\n",
        "    if H in training_histories:\n",
        "        history_file = os.path.join(results_dir, f\"training_history_H{H}.npz\")\n",
        "        np.savez(history_file, **training_histories[H])\n",
        "        print(f\"Training history for H={H} saved to {history_file}\")\n",
        "\n",
        "print(f\"\\nAll results saved successfully!\")\n",
        "print(f\"Results directory: {results_dir}\")\n",
        "print(f\"Files created:\")\n",
        "print(f\"  - fast_tokenizer_results.json (comprehensive results)\")\n",
        "print(f\"  - fast_model_H*.pth (trained models)\")\n",
        "print(f\"  - training_history_H*.npz (training curves)\")\n",
        "\n",
        "# Print final summary\n",
        "print(f\"\\nFinal Summary:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Sampling rates tested: {sampling_rates}\")\n",
        "print(f\"Total sequences generated: {num_sequences * len(sampling_rates)}\")\n",
        "print(f\"Models trained: {len(sampling_rates)}\")\n",
        "print(f\"Average training time: {np.mean([training_results[H]['training_time'] for H in sampling_rates]):.1f}s\")\n",
        "print(f\"Best MSE: {min([training_results[H]['mse'] for H in sampling_rates]):.6f} (H={min(sampling_rates)})\")\n",
        "print(f\"Worst MSE: {max([training_results[H]['mse'] for H in sampling_rates]):.6f} (H={max(sampling_rates)})\")\n",
        "\n",
        "print(f\"\\nFAST Tokenizer training and inference completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
