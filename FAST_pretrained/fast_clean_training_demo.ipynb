{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PARAMETERS - MODIFY THESE AS NEEDED\n",
        "# =============================================================================\n",
        "\n",
        "# Dataset parameters\n",
        "NUM_SEQUENCES = 10000\n",
        "SEQUENCE_LENGTH = 800\n",
        "SEED = 42\n",
        "\n",
        "# Tokenization parameters\n",
        "MAX_TOKEN_LENGTH = 40  # Maximum length for padding\n",
        "PAD_TOKEN = 0\n",
        "VOCAB_SIZE = 2048  # FAST tokenizer vocabulary size\n",
        "\n",
        "# Model parameters\n",
        "D_MODEL = 128\n",
        "NHEAD = 8\n",
        "NUM_LAYERS = 4\n",
        "MAX_SEQ_LEN = 50\n",
        "CONDITIONING_DIM = 8  # 4 points * 2 (time, value)\n",
        "\n",
        "# Training parameters\n",
        "NUM_EPOCHS = 100\n",
        "LEARNING_RATE = 1e-3\n",
        "WEIGHT_DECAY = 1e-5\n",
        "BATCH_SIZE = 32\n",
        "PATIENCE = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Configuration:\n",
            "  - Dataset: 10,000 sequences, length 800\n",
            "  - Tokenization: max_length=40, vocab_size=1024\n",
            "  - Model: d_model=128, nhead=8, layers=4\n",
            "  - Training: epochs=100, lr=0.001, batch_size=32\n",
            "  - Device: cuda\n",
            "‚úÖ Setup complete!\n",
            "üîÑ Generating dataset with 10,000 sequences of length 800...\n",
            "‚úÖ Dataset generated successfully!\n",
            "üìä Dataset Statistics:\n",
            "  - Shape: (10000, 800)\n",
            "  - Data range: [-8.000, 8.000]\n",
            "  - Mean: -0.845, Std: 3.771\n",
            "  - Conditioning shape: (10000, 4, 2)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Device\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "print(f\"üìä Configuration:\")\n",
        "print(f\"  - Dataset: {NUM_SEQUENCES:,} sequences, length {SEQUENCE_LENGTH}\")\n",
        "print(f\"  - Tokenization: max_length={MAX_TOKEN_LENGTH}, vocab_size={VOCAB_SIZE}\")\n",
        "print(f\"  - Model: d_model={D_MODEL}, nhead={NHEAD}, layers={NUM_LAYERS}\")\n",
        "print(f\"  - Training: epochs={NUM_EPOCHS}, lr={LEARNING_RATE}, batch_size={BATCH_SIZE}\")\n",
        "print(f\"  - Device: {DEVICE}\")\n",
        "\n",
        "# Set up matplotlib for better plots\n",
        "plt.style.use('default')\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "# Import our modules\n",
        "from cubic_spline_generator import CubicSplineGenerator\n",
        "from fast_tokenizer import FASTTokenizer\n",
        "from transformer_model import SimpleTransformer\n",
        "\n",
        "print(\"‚úÖ Setup complete!\")\n",
        "\n",
        "print(f\"üîÑ Generating dataset with {NUM_SEQUENCES:,} sequences of length {SEQUENCE_LENGTH}...\")\n",
        "\n",
        "# Initialize generator\n",
        "generator = CubicSplineGenerator(seed=SEED)\n",
        "\n",
        "# Generate data\n",
        "times, targets, conditioning = generator.generate_spline_data(\n",
        "    num_sequences=NUM_SEQUENCES,\n",
        "    sequence_length=SEQUENCE_LENGTH\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Dataset generated successfully!\")\n",
        "print(f\"üìä Dataset Statistics:\")\n",
        "print(f\"  - Shape: {targets.shape}\")\n",
        "print(f\"  - Data range: [{targets.min():.3f}, {targets.max():.3f}]\")\n",
        "print(f\"  - Mean: {targets.mean():.3f}, Std: {targets.std():.3f}\")\n",
        "print(f\"  - Conditioning shape: {conditioning.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Loading pretrained FAST tokenizer...\n",
            "Loading pretrained FAST tokenizer (no training)...\n",
            "Pretrained FAST tokenizer loaded successfully!\n",
            "Action dimension: 1\n",
            "Time horizon: 800\n",
            "‚úÖ Pretrained FAST tokenizer loaded successfully!\n",
            "üìä Tokenizer Info:\n",
            "  - Action dimension: 1\n",
            "  - Time horizon: 800\n",
            "  - Normalization: q1=-7.541, q99=6.927\n",
            "  - Note: Using pretrained weights from 'physical-intelligence/fast', no training performed\n"
          ]
        }
      ],
      "source": [
        "print(\"üîß Fitting FAST tokenizer...\")\n",
        "\n",
        "# Initialize and fit FAST tokenizer\n",
        "fast_tokenizer = FASTTokenizer()\n",
        "fast_tokenizer.fit(targets)\n",
        "\n",
        "print(f\"‚úÖ FAST tokenizer fitted successfully!\")\n",
        "print(f\"üìä Tokenizer Info:\")\n",
        "print(f\"  - Action dimension: {fast_tokenizer.action_dim}\")\n",
        "print(f\"  - Time horizon: {fast_tokenizer.time_horizon}\")\n",
        "print(f\"  - Normalization: q1={fast_tokenizer._q1:.3f}, q99={fast_tokenizer._q99:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üèóÔ∏è Initializing model and training setup...\n",
            "‚úÖ Model created with 1,057,408 parameters\n",
            "‚úÖ Training setup complete!\n"
          ]
        }
      ],
      "source": [
        "print(\"üèóÔ∏è Initializing model and training setup...\")\n",
        "\n",
        "# Initialize model\n",
        "model = SimpleTransformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    d_model=D_MODEL,\n",
        "    nhead=NHEAD,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    max_seq_len=MAX_SEQ_LEN,\n",
        "    conditioning_dim=CONDITIONING_DIM\n",
        ").to(DEVICE)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"‚úÖ Model created with {total_params:,} parameters\")\n",
        "\n",
        "\n",
        "# Initialize trainer\n",
        "from training import FASTTrainer\n",
        "trainer = FASTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=fast_tokenizer,\n",
        "    device=DEVICE,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    weight_decay=WEIGHT_DECAY,\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    pad_token=PAD_TOKEN\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Training setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Preparing training data...\n",
            "‚úÖ Data prepared successfully!\n",
            "üìä Data Statistics:\n",
            "  - Train batches: 250\n",
            "  - Val batches: 63\n",
            "  - Batch size: 32\n",
            "  - Token shape: torch.Size([32, 45])\n",
            "  - Conditioning shape: torch.Size([32, 4, 2])\n",
            "  - Attention mask shape: torch.Size([32, 45])\n",
            "  - Attention mask ratio (True): 0.361\n"
          ]
        }
      ],
      "source": [
        "print(\"üìä Preparing training data...\")\n",
        "\n",
        "# Prepare data with tokenization and attention masks\n",
        "train_loader, val_loader = trainer.prepare_data(\n",
        "    times=times,\n",
        "    targets=targets,\n",
        "    conditioning=conditioning,\n",
        "    train_ratio=0.8\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Data prepared successfully!\")\n",
        "print(f\"üìä Data Statistics:\")\n",
        "print(f\"  - Train batches: {len(train_loader)}\")\n",
        "print(f\"  - Val batches: {len(val_loader)}\")\n",
        "print(f\"  - Batch size: {BATCH_SIZE}\")\n",
        "\n",
        "# Show sample batch info\n",
        "for batch_tokens, batch_conditioning, batch_attention_mask in train_loader:\n",
        "    print(f\"  - Token shape: {batch_tokens.shape}\")\n",
        "    print(f\"  - Conditioning shape: {batch_conditioning.shape}\")\n",
        "    print(f\"  - Attention mask shape: {batch_attention_mask.shape}\")\n",
        "    print(f\"  - Attention mask ratio (True): {batch_attention_mask.float().mean():.3f}\")\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Starting training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [78,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# Train epoch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     train_loss = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     train_losses.append(train_loss)\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# Validate\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/action_tokenization/FAST_pretrained/training.py:155\u001b[39m, in \u001b[36mFASTTrainer.train_epoch\u001b[39m\u001b[34m(self, train_loader)\u001b[39m\n\u001b[32m    152\u001b[39m batch_attention_mask = batch_attention_mask.to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m    154\u001b[39m \u001b[38;5;66;03m# Forward pass with attention mask\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_sequence\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconditioning_points\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_conditioning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpad_token\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpad_token\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;66;03m# Create targets (shifted by 1 for next token prediction)\u001b[39;00m\n\u001b[32m    163\u001b[39m targets = batch_tokens[:, \u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# Remove first token\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/action_tokenization/FAST_pretrained/transformer_model.py:129\u001b[39m, in \u001b[36mSimpleTransformer.forward\u001b[39m\u001b[34m(self, token_sequence, conditioning_points, attention_mask, pad_token)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;66;03m# Embed conditioning points\u001b[39;00m\n\u001b[32m    128\u001b[39m conditioning_flat = conditioning_points.view(batch_size, -\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# [batch_size, 8]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m conditioning_emb = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconditioning_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconditioning_flat\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch_size, d_model]\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[38;5;66;03m# Add conditioning to all positions (broadcast)\u001b[39;00m\n\u001b[32m    132\u001b[39m conditioning_emb = conditioning_emb.unsqueeze(\u001b[32m1\u001b[39m).expand(-\u001b[32m1\u001b[39m, seq_len, -\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# [batch_size, seq_len, d_model]\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mRuntimeError\u001b[39m: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`"
          ]
        }
      ],
      "source": [
        "print(\"üöÄ Starting training...\")\n",
        "\n",
        "# Training history\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # Train epoch\n",
        "    train_loss = trainer.train_epoch(train_loader)\n",
        "    train_losses.append(train_loss)\n",
        "    \n",
        "    # Validate\n",
        "    val_loss = trainer.validate(val_loader)\n",
        "    val_losses.append(val_loss)\n",
        "    \n",
        "    # Print progress\n",
        "    if epoch % 10 == 0 or epoch == NUM_EPOCHS - 1:\n",
        "        print(f\"Epoch {epoch:3d}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
        "    \n",
        "    # Early stopping\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        patience_counter = 0\n",
        "        # Save best model\n",
        "        torch.save(model.state_dict(), 'best_fast_model.pth')\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(f\"üõë Early stopping at epoch {epoch}\")\n",
        "            break\n",
        "\n",
        "print(f\"‚úÖ Training completed!\")\n",
        "print(f\"üìä Final Results:\")\n",
        "print(f\"  - Best validation loss: {best_val_loss:.4f}\")\n",
        "print(f\"  - Final train loss: {train_losses[-1]:.4f}\")\n",
        "print(f\"  - Final val loss: {val_losses[-1]:.4f}\")\n",
        "print(f\"  - Total epochs: {len(train_losses)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Evaluating model on validation set...\n"
          ]
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 626.00 MiB. GPU 0 has a total capacity of 1.83 GiB of which 568.25 MiB is free. Including non-PyTorch memory, this process has 1.26 GiB memory in use. Of the allocated memory 764.30 MiB is allocated by PyTorch, and 457.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müîç Evaluating model on validation set...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Evaluate on validation set (need to pass raw data, not data loader)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m val_mse = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate_mse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconditioning\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconditioning\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Validation MSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_mse\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Generate predictions for visualization\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/action_tokenization/FAST/training.py:296\u001b[39m, in \u001b[36mFASTTrainer.evaluate_mse\u001b[39m\u001b[34m(self, times, targets, conditioning)\u001b[39m\n\u001b[32m    294\u001b[39m \u001b[38;5;66;03m# Generate predictions using FAST tokenizer\u001b[39;00m\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m     predicted_tokens = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconditioning_points\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconditioning_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Match the max_length used in training\u001b[39;49;00m\n\u001b[32m    299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Deterministic generation\u001b[39;49;00m\n\u001b[32m    300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[38;5;66;03m# Convert back to continuous values using FAST detokenization\u001b[39;00m\n\u001b[32m    305\u001b[39m predicted_continuous = \u001b[38;5;28mself\u001b[39m.tokenizer.detokenize_with_padding(\n\u001b[32m    306\u001b[39m     predicted_tokens.cpu().numpy(), pad_token=\u001b[38;5;28mself\u001b[39m.pad_token\n\u001b[32m    307\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/action_tokenization/FAST/transformer_model.py:222\u001b[39m, in \u001b[36mSimpleTransformer.generate\u001b[39m\u001b[34m(self, conditioning_points, max_length, temperature, device, greedy, start_tokens, tokenizer)\u001b[39m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# Create attention mask for current tokens (all True since they're real tokens)\u001b[39;00m\n\u001b[32m    221\u001b[39m     current_mask = torch.ones(batch_size, current_tokens.shape[\u001b[32m1\u001b[39m], dtype=torch.bool, device=device)\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m     logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken_sequence\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurrent_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconditioning_points\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconditioning_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurrent_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_token\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\n\u001b[32m    227\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    228\u001b[39m     next_token_logits = logits[:, -\u001b[32m1\u001b[39m, :]\n\u001b[32m    230\u001b[39m \u001b[38;5;66;03m# Select next token\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/action_tokenization/FAST/transformer_model.py:155\u001b[39m, in \u001b[36mSimpleTransformer.forward\u001b[39m\u001b[34m(self, token_sequence, conditioning_points, attention_mask, pad_token)\u001b[39m\n\u001b[32m    152\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.transformer(x, mask=causal_mask, src_key_padding_mask=src_key_padding_mask)\n\u001b[32m    154\u001b[39m \u001b[38;5;66;03m# Project to vocabulary\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moutput_projection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch_size, seq_len, vocab_size]\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 626.00 MiB. GPU 0 has a total capacity of 1.83 GiB of which 568.25 MiB is free. Including non-PyTorch memory, this process has 1.26 GiB memory in use. Of the allocated memory 764.30 MiB is allocated by PyTorch, and 457.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "# Load best model\n",
        "model.load_state_dict(torch.load('best_fast_model.pth'))\n",
        "model.eval()\n",
        "\n",
        "print(\"üîç Evaluating model on validation set...\")\n",
        "\n",
        "# Evaluate on validation set (need to pass raw data, not data loader)\n",
        "val_mse = trainer.evaluate_mse(\n",
        "    times=times,\n",
        "    targets=targets, \n",
        "    conditioning=conditioning\n",
        ")\n",
        "print(f\"‚úÖ Validation MSE: {val_mse:.6f}\")\n",
        "\n",
        "# Generate predictions for visualization\n",
        "print(\"üéØ Generating predictions for visualization...\")\n",
        "\n",
        "# Get a few samples from validation set\n",
        "val_samples = []\n",
        "for batch_tokens, batch_conditioning, batch_attention_mask in val_loader:\n",
        "    val_samples.append((batch_tokens[:3], batch_conditioning[:3], batch_attention_mask[:3]))\n",
        "    if len(val_samples) >= 1:  # Just take first batch\n",
        "        break\n",
        "\n",
        "# Generate predictions\n",
        "with torch.no_grad():\n",
        "    predictions = []\n",
        "    targets = []\n",
        "    \n",
        "    for batch_tokens, batch_conditioning, batch_attention_mask in val_samples:\n",
        "        # Generate sequences using greedy=True (same as binning case study)\n",
        "        generated_tokens = model.generate(\n",
        "            conditioning_points=batch_conditioning,\n",
        "            max_length=MAX_TOKEN_LENGTH,\n",
        "            greedy=True,  # Deterministic generation using argmax\n",
        "            device=DEVICE,\n",
        "            tokenizer=fast_tokenizer\n",
        "        )\n",
        "        \n",
        "        # Convert back to continuous values\n",
        "        for i in range(generated_tokens.shape[0]):\n",
        "            # Detokenize generated sequence\n",
        "            pred_sequence = fast_tokenizer.detokenize_with_padding(\n",
        "                generated_tokens[i].cpu().numpy(),\n",
        "                pad_token=PAD_TOKEN\n",
        "            )\n",
        "            predictions.append(pred_sequence)\n",
        "            \n",
        "            # Get original target\n",
        "            target_sequence = fast_tokenizer.detokenize_with_padding(\n",
        "                batch_tokens[i].cpu().numpy(),\n",
        "                pad_token=PAD_TOKEN\n",
        "            )\n",
        "            targets.append(target_sequence)\n",
        "\n",
        "print(f\"‚úÖ Generated {len(predictions)} prediction sequences\")\n",
        "print(f\"üìä Prediction Statistics:\")\n",
        "print(f\"  - Prediction shape: {predictions[0].shape}\")\n",
        "print(f\"  - Target shape: {targets[0].shape}\")\n",
        "print(f\"  - Prediction range: [{np.array(predictions).min():.3f}, {np.array(predictions).max():.3f}]\")\n",
        "print(f\"  - Target range: [{np.array(targets).min():.3f}, {np.array(targets).max():.3f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Prediction Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'predictions' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m fig, axes = plt.subplots(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m, figsize=(\u001b[32m15\u001b[39m, \u001b[32m10\u001b[39m))\n\u001b[32m      3\u001b[39m axes = axes.flatten()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mmin\u001b[39m(\u001b[32m4\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mpredictions\u001b[49m))):\n\u001b[32m      6\u001b[39m     ax = axes[i]\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# Plot target and prediction\u001b[39;00m\n",
            "\u001b[31mNameError\u001b[39m: name 'predictions' is not defined"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x1000 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualize predictions vs targets\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i in range(min(4, len(predictions))):\n",
        "    ax = axes[i]\n",
        "    \n",
        "    # Plot target and prediction\n",
        "    ax.plot(targets[i], label='Target', alpha=0.8, linewidth=2)\n",
        "    ax.plot(predictions[i], label='Prediction', alpha=0.8, linewidth=2, linestyle='--')\n",
        "    \n",
        "    # Calculate MSE for this sequence\n",
        "    mse = np.mean((targets[i] - predictions[i])**2)\n",
        "    \n",
        "    ax.set_title(f'Sequence {i+1} (MSE: {mse:.4f})')\n",
        "    ax.set_xlabel('Time Step')\n",
        "    ax.set_ylabel('Value')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate overall statistics\n",
        "all_targets = np.concatenate(targets)\n",
        "all_predictions = np.concatenate(predictions)\n",
        "overall_mse = np.mean((all_targets - all_predictions)**2)\n",
        "overall_mae = np.mean(np.abs(all_targets - all_predictions))\n",
        "\n",
        "print(f\"üìä Overall Prediction Statistics:\")\n",
        "print(f\"  - Overall MSE: {overall_mse:.6f}\")\n",
        "print(f\"  - Overall MAE: {overall_mae:.6f}\")\n",
        "print(f\"  - Correlation: {np.corrcoef(all_targets, all_predictions)[0,1]:.4f}\")\n",
        "\n",
        "# Plot correlation\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(all_targets, all_predictions, alpha=0.5, s=1)\n",
        "plt.plot([all_targets.min(), all_targets.max()], [all_targets.min(), all_targets.max()], 'r--', alpha=0.8)\n",
        "plt.xlabel('Target Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title(f'Target vs Prediction Correlation (r={np.corrcoef(all_targets, all_predictions)[0,1]:.4f})')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "llm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
